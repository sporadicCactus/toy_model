{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpy\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Item:\n",
    "    \n",
    "    def __init__(self, source_id, pipeline, frame_num=None):\n",
    "        self.source_id = source_id\n",
    "        self.pipeline = pipeline\n",
    "        self.frame_num = frame_num\n",
    "        self._pos = 0\n",
    "        \n",
    "    @property\n",
    "    def work_type(self):\n",
    "        if self._pos < len(self.pipeline):\n",
    "            return self.pipeline[self._pos]\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def next_work(self):\n",
    "        self._pos += 1\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"<source: {self.source_id}, frame: {self.frame_num}>\"\n",
    "\n",
    "        \n",
    "class Context:\n",
    "    \n",
    "    def __init__(self, env, worker, source_id, work_type, compute_time):\n",
    "        self.env = env\n",
    "        self.worker = worker\n",
    "        self.source_id = source_id\n",
    "        self.work_type = work_type\n",
    "        self.compute_time = compute_time\n",
    "        self.input_buffer = simpy.Store(env)\n",
    "        self.output_buffer = simpy.Store(env)\n",
    "        self.process = env.process(self.run())\n",
    "        \n",
    "    def put(self, item):\n",
    "        self.input_buffer.put(item)\n",
    "        \n",
    "    def run(self):\n",
    "        while True:\n",
    "            try:\n",
    "                item = yield self.input_buffer.get()\n",
    "                assert item.work_type == self.work_type and item.source_id == self.source_id\n",
    "                with self.worker.compute.request() as compute:\n",
    "                    yield compute\n",
    "                    yield self.env.timeout(self.compute_time)\n",
    "                    item = item.next_work()\n",
    "                    self.worker.output_buffer.put(item)\n",
    "            except:\n",
    "                return\n",
    "            \n",
    "    def kill(self):\n",
    "        self.process.interrupt()\n",
    "\n",
    "\n",
    "class Worker:\n",
    "    _counter = 0\n",
    "    _instances = {}\n",
    "    \n",
    "    def __init__(self, env, coordinator, ability, compute_capacity):\n",
    "        self.env = env\n",
    "        self.coordinator = coordinator\n",
    "        self.ability = ability\n",
    "        self.compute = simpy.Resource(env, capacity=compute_capacity)\n",
    "        self.input_buffer = simpy.Store(env)\n",
    "        self.output_buffer = simpy.Store(env)\n",
    "        self.contexts = {}\n",
    "        self.routing_table = {}\n",
    "        \n",
    "        self.id = self._counter\n",
    "        self._instances[self._counter] = self\n",
    "        self.__class__._counter += 1\n",
    "        \n",
    "        self.process = env.process(self.run())\n",
    "        \n",
    "    def run(self):\n",
    "        inp = self.input_buffer.get()\n",
    "        out = self.output_buffer.get()\n",
    "        while True:\n",
    "            try:\n",
    "                res = yield inp | out\n",
    "                if inp in res:\n",
    "                    item = res[inp]\n",
    "                    context = self.contexts.get((item.source_id, item.work_type))\n",
    "                    if context is None:\n",
    "                        self.add_context(item.source_id, item.work_type)\n",
    "                        context = self.contexts[(item.source_id, item.work_type)]\n",
    "                    context.put(item)\n",
    "                    inp = self.input_buffer.get()\n",
    "                if out in res:\n",
    "                    item = res[out]\n",
    "                    source_id, work_type = item.source_id, item.work_type\n",
    "                    if work_type is None:\n",
    "                        self.coordinator.fully_processed_items.append(item)\n",
    "                    else:\n",
    "                        receiver_id = self.routing_table.get((source_id, work_type))\n",
    "                        if receiver_id is None:\n",
    "                            receiver_id = self.coordinator.request_route(self.id, source_id, work_type)\n",
    "                            self.routing_table[(source_id, work_type)] = receiver_id\n",
    "                        self.__class__.send_item(to=receiver_id, item=item)\n",
    "                    out = self.output_buffer.get()\n",
    "            except:\n",
    "                return\n",
    "                \n",
    "    def kill(self):\n",
    "        for context in self.contexts.values():\n",
    "            context.kill()\n",
    "        self.process.interrupt()\n",
    "            \n",
    "    def put(self, item):\n",
    "        self.input_buffer.put(item)\n",
    "            \n",
    "    def add_context(self, source_id, work_type):\n",
    "        assert work_type in self.ability\n",
    "        context = Context(self.env, self, source_id, work_type, self.ability[work_type])\n",
    "        self.contexts[(source_id, work_type)] = context\n",
    "        return context\n",
    "        \n",
    "    def remove_context(self, source_id, work_type=None):\n",
    "        work_types = [\n",
    "            work_type_ for source_id_, work_type_ in self.contexts.keys()\n",
    "            if source_id_==source_id\n",
    "        ] if work_type is None else [work_type]\n",
    "        for work_type in work_types:\n",
    "            context = self.contexts.pop((source_id, work_type))\n",
    "            context.process.interrupt()\n",
    "        \n",
    "    @classmethod\n",
    "    def send_item(cls, to, item):\n",
    "        cls._instances[to].put(item)\n",
    "        \n",
    "    @classmethod\n",
    "    def move_context(cls, to, fr, source_id, work_type):\n",
    "        src_worker = Worker._instances[fr]\n",
    "        dst_worker = Worker._instances[to]\n",
    "        src_context = src_worker.contexts[(source_id, work_type)]\n",
    "        \n",
    "        dst_context = dst_worker.add_context(source_id, work_type)\n",
    "        for item in src_context.input_buffer.items:\n",
    "            dst_context.put(item)\n",
    "        src_worker.remove_context(source_id, work_type)\n",
    "        \n",
    "        \n",
    "class Source:\n",
    "    _counter = 0\n",
    "    _instances = {}\n",
    "    \n",
    "    def __init__(self, env, pipeline, receiver_id=None):\n",
    "        self.env = env\n",
    "        self.pipeline = pipeline\n",
    "        self.receiver_id = receiver_id\n",
    "        \n",
    "        self.id = self._counter\n",
    "        self._instances[self._counter] = self\n",
    "        self.__class__._counter += 1\n",
    "        \n",
    "        self.frame_counter = 0\n",
    "        \n",
    "        self.process = env.process(self.run())\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            try:\n",
    "                n_frames = random.randint(1, 30)\n",
    "                for _ in range(n_frames):\n",
    "                    if self.receiver_id is not None:\n",
    "                        Worker.send_item(\n",
    "                            to=self.receiver_id,\n",
    "                            item=Item(self.id, copy.copy(self.pipeline), self.frame_counter)\n",
    "                        )\n",
    "                        self.frame_counter += 1\n",
    "                    yield self.env.timeout(1.0)\n",
    "                idle = 30*random.random()\n",
    "                yield self.env.timeout(idle)\n",
    "            except simpy.Interrupt:\n",
    "                return\n",
    "            \n",
    "    def kill(self):\n",
    "        self.process.interrupt()\n",
    "        \n",
    "class Coordinator:\n",
    "    \n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.workers = []\n",
    "        self.sources = []\n",
    "        self.routing_table = {}\n",
    "        self.fully_processed_items = []\n",
    "        \n",
    "        self.process = env.process(self.monitor(5.))\n",
    "        \n",
    "    def monitor(self, timeout):\n",
    "        while True:\n",
    "            yield self.env.timeout(timeout)\n",
    "            print(\"----------\")\n",
    "            print(f\"Now: {self.env.now}\")\n",
    "            print(f\"Total queue size: {self.total_queue_size}\")\n",
    "            print(f\"Total processed: {self.total_processed}\")\n",
    "        \n",
    "    def get_able_worker_id(self, work_type):\n",
    "        able_worker_ids = [\n",
    "            worker.id for worker in self.workers\n",
    "            if work_type in worker.ability\n",
    "        ]\n",
    "        num_jobs = Counter([path[\"dst\"] for path in self.routing_table.values()])\n",
    "        num_jobs.update([source.receiver_id for source in self.sources])\n",
    "        worker_id, _ = min(\n",
    "            [(worker_id, num_jobs[worker_id]) for worker_id in able_worker_ids],\n",
    "            key=lambda pair: pair[1]\n",
    "        )\n",
    "        return worker_id\n",
    "        \n",
    "    def add_source(self, pipeline):\n",
    "        receiver_id = self.get_able_worker_id(pipeline[0])\n",
    "        source = Source(self.env, pipeline, receiver_id)\n",
    "        self.sources.append(source)\n",
    "        \n",
    "    def remove_source(self, source_id):\n",
    "        source = Source._instances[source_id]\n",
    "        source.kill()\n",
    "        self.sources.remove(source)\n",
    "        for worker in self.workers:\n",
    "            worker.remove_context(source.id)\n",
    "        for work_type in source.pipeline:\n",
    "            if (source.id, work_type) in self.routing_table:\n",
    "                self.routing_table.pop((source.id, work_type))\n",
    "        \n",
    "    def add_worker(self, ability, compute_capacity):\n",
    "        worker = Worker(self.env, self, ability, compute_capacity)\n",
    "        self.workers.append(worker)\n",
    "        \n",
    "    def remove_worker(self, worker_id):\n",
    "        worker = Worker._instances[worker_id]\n",
    "        worker.kill()\n",
    "        self.workers.remove(worker)\n",
    "        keys = [key for key, path in self.routing_table.items() if worker_id in path.values()]\n",
    "        for key in keys:\n",
    "            self.routing_table.pop(key)\n",
    "        for source in self.sources:\n",
    "            if source.receiver_id == worker_id:\n",
    "                source.receiver_id = self.get_able_worker_id(source.pipeline[0])\n",
    "        \n",
    "    def request_route(self, worker_id, source_id, work_type):\n",
    "        path = self.routing_table.get((source_id, work_type))\n",
    "        if path:\n",
    "            assert path[\"src\"] == worker_id\n",
    "            return path[\"dst\"]\n",
    "        else:\n",
    "            receiver_id = self.get_able_worker_id(work_type)\n",
    "            path = {\"src\": worker_id, \"dst\": receiver_id}\n",
    "            self.routing_table[(source_id, work_type)] = path\n",
    "            return receiver_id\n",
    "\n",
    "    @property\n",
    "    def processing_chains(self):\n",
    "        chains = []\n",
    "        for source in self.sources:\n",
    "            chain = [f's{source.id}']\n",
    "            worker_id = source.receiver_id\n",
    "            chain.append(f'w{worker_id}')\n",
    "            for work_type in source.pipeline[1:]:\n",
    "                if (source.id, work_type) in self.routing_table:\n",
    "                    worker_id = self.routing_table[(source.id, work_type)]['dst']\n",
    "                    chain.append(f'w{worker_id}')\n",
    "                else:\n",
    "                    choin.append('*')\n",
    "            chain = ' -> '.join(chain)\n",
    "            chains.append(chain)\n",
    "        return chains\n",
    "    \n",
    "    @property\n",
    "    def total_queue_size(self):\n",
    "        queue_size = 0\n",
    "        for worker in self.workers:\n",
    "            for context in worker.contexts.values():\n",
    "                queue_size += len(context.input_buffer.items)\n",
    "        return queue_size\n",
    "    \n",
    "    @property\n",
    "    def total_processed(self):\n",
    "        return len(self.fully_processed_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Now: 5.0\n",
      "Total queue size: 0\n",
      "Total processed: 8\n",
      "----------\n",
      "Now: 10.0\n",
      "Total queue size: 0\n",
      "Total processed: 18\n",
      "----------\n",
      "Now: 15.0\n",
      "Total queue size: 0\n",
      "Total processed: 28\n",
      "----------\n",
      "Now: 20.0\n",
      "Total queue size: 0\n",
      "Total processed: 36\n",
      "----------\n",
      "Now: 25.0\n",
      "Total queue size: 0\n",
      "Total processed: 47\n",
      "----------\n",
      "Now: 30.0\n",
      "Total queue size: 1\n",
      "Total processed: 61\n",
      "----------\n",
      "Now: 35.0\n",
      "Total queue size: 1\n",
      "Total processed: 70\n",
      "----------\n",
      "Now: 40.0\n",
      "Total queue size: 1\n",
      "Total processed: 76\n",
      "----------\n",
      "Now: 45.0\n",
      "Total queue size: 3\n",
      "Total processed: 98\n",
      "----------\n",
      "Now: 50.0\n",
      "Total queue size: 5\n",
      "Total processed: 124\n",
      "----------\n",
      "Now: 55.0\n",
      "Total queue size: 4\n",
      "Total processed: 146\n",
      "----------\n",
      "Source 0 removed\n",
      "----------\n",
      "Now: 60.0\n",
      "Total queue size: 5\n",
      "Total processed: 172\n",
      "----------\n",
      "Now: 65.0\n",
      "Total queue size: 3\n",
      "Total processed: 192\n",
      "----------\n",
      "Now: 70.0\n",
      "Total queue size: 0\n",
      "Total processed: 209\n",
      "----------\n",
      "Now: 75.0\n",
      "Total queue size: 0\n",
      "Total processed: 219\n",
      "----------\n",
      "Routing:\n",
      "s1 -> w1 -> w4\n",
      "s2 -> w2 -> w3 -> w5\n",
      "s3 -> w0 -> w4 -> w6\n",
      "s4 -> w1 -> w5\n",
      "s5 -> w2 -> w6\n",
      "s6 -> w0 -> w5\n",
      "s7 -> w1 -> w6\n",
      "----------\n",
      "Workers 2, 3 removed.\n",
      "----------\n",
      "Now: 80.0\n",
      "Total queue size: 0\n",
      "Total processed: 230\n",
      "----------\n",
      "Now: 85.0\n",
      "Total queue size: 0\n",
      "Total processed: 245\n",
      "----------\n",
      "Now: 90.0\n",
      "Total queue size: 0\n",
      "Total processed: 258\n",
      "----------\n",
      "Now: 95.0\n",
      "Total queue size: 0\n",
      "Total processed: 275\n",
      "----------\n",
      "Routing:\n",
      "s1 -> w1 -> w4\n",
      "s2 -> w0 -> w4 -> w5\n",
      "s3 -> w0 -> w4 -> w6\n",
      "s4 -> w1 -> w5\n",
      "s5 -> w0 -> w6\n",
      "s6 -> w0 -> w5\n",
      "s7 -> w1 -> w6\n",
      "----------\n",
      "Worker 1 removed.\n",
      "----------\n",
      "Now: 100.0\n",
      "Total queue size: 0\n",
      "Total processed: 289\n",
      "----------\n",
      "Now: 105.0\n",
      "Total queue size: 8\n",
      "Total processed: 299\n",
      "----------\n",
      "Now: 110.0\n",
      "Total queue size: 19\n",
      "Total processed: 308\n",
      "----------\n",
      "Now: 115.0\n",
      "Total queue size: 31\n",
      "Total processed: 318\n",
      "----------\n",
      "Now: 120.0\n",
      "Total queue size: 47\n",
      "Total processed: 328\n",
      "----------\n",
      "Now: 125.0\n",
      "Total queue size: 58\n",
      "Total processed: 338\n",
      "----------\n",
      "Now: 130.0\n",
      "Total queue size: 60\n",
      "Total processed: 348\n",
      "----------\n",
      "Now: 135.0\n",
      "Total queue size: 60\n",
      "Total processed: 358\n",
      "----------\n",
      "Routing:\n",
      "s1 -> w0 -> w4\n",
      "s2 -> w0 -> w4 -> w5\n",
      "s3 -> w0 -> w4 -> w6\n",
      "s4 -> w0 -> w6\n",
      "s5 -> w0 -> w6\n",
      "s6 -> w0 -> w5\n",
      "s7 -> w0 -> w5\n"
     ]
    }
   ],
   "source": [
    "env = simpy.Environment()\n",
    "coordinator = Coordinator(env)\n",
    "coordinator.add_worker({'preprocess': 0.5}, compute_capacity=1)\n",
    "coordinator.add_worker({'preprocess': 0.5}, compute_capacity=1)\n",
    "coordinator.add_worker({'preprocess': 0.5}, compute_capacity=1)\n",
    "coordinator.add_worker({'process': 1}, compute_capacity=3)\n",
    "coordinator.add_worker({'process': 1}, compute_capacity=3)\n",
    "coordinator.add_worker({'postprocess': 0.5}, compute_capacity=1)\n",
    "coordinator.add_worker({'postprocess': 0.5}, compute_capacity=1)\n",
    "\n",
    "\n",
    "coordinator.add_source(('preprocess', 'process'))\n",
    "coordinator.add_source(('preprocess', 'process'))\n",
    "env.run(until=20)\n",
    "coordinator.add_source(('preprocess', 'process', 'postprocess'))\n",
    "coordinator.add_source(('preprocess', 'process', 'postprocess'))\n",
    "env.run(until=40)\n",
    "coordinator.add_source(('preprocess', 'postprocess'))\n",
    "coordinator.add_source(('preprocess', 'postprocess'))\n",
    "coordinator.add_source(('preprocess', 'postprocess'))\n",
    "coordinator.add_source(('preprocess', 'postprocess'))\n",
    "env.run(until=60)\n",
    "coordinator.remove_source(0)\n",
    "print(\"----------\")\n",
    "print(\"Source 0 removed\")\n",
    "env.run(until=80)\n",
    "print(\"----------\")\n",
    "print(\"Routing:\")\n",
    "print(*coordinator.processing_chains, sep='\\n')\n",
    "coordinator.remove_worker(2)\n",
    "coordinator.remove_worker(3)\n",
    "print(\"----------\")\n",
    "print(\"Workers 2, 3 removed.\")\n",
    "env.run(until=100)\n",
    "print(\"----------\")\n",
    "print(\"Routing:\")\n",
    "print(*coordinator.processing_chains, sep='\\n')\n",
    "coordinator.remove_worker(1)\n",
    "print(\"----------\")\n",
    "print(\"Worker 1 removed.\")\n",
    "env.run(until=140)\n",
    "print(\"----------\")\n",
    "print(\"Routing:\")\n",
    "print(*coordinator.processing_chains, sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt3.7",
   "language": "python",
   "name": "pt3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
